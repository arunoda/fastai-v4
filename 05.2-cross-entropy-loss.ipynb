{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy Loss\n",
    "\n",
    "**WTF**. It's sounds scary. But this is a way to create a loss function for model based on categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Linear MNIST Model\n",
    "\n",
    "First of all, let's create a Linear MNIST model we create in lesson 4. <br/>\n",
    "We can build stuff on top of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/storage/data/mnist_png/training'),Path('/storage/data/mnist_png/testing')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [Path('/storage/data/mnist_png/training/9'),Path('/storage/data/mnist_png/training/6'),Path('/storage/data/mnist_png/training/7'),Path('/storage/data/mnist_png/training/0'),Path('/storage/data/mnist_png/training/4'),Path('/storage/data/mnist_png/training/5'),Path('/storage/data/mnist_png/training/3'),Path('/storage/data/mnist_png/training/2'),Path('/storage/data/mnist_png/training/1'),Path('/storage/data/mnist_png/training/8')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(im_path/\"training\").ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5949) [Path('/storage/data/mnist_png/training/9/39927.png'),Path('/storage/data/mnist_png/training/9/52230.png'),Path('/storage/data/mnist_png/training/9/39692.png'),Path('/storage/data/mnist_png/training/9/33246.png'),Path('/storage/data/mnist_png/training/9/59344.png'),Path('/storage/data/mnist_png/training/9/14364.png'),Path('/storage/data/mnist_png/training/9/53342.png'),Path('/storage/data/mnist_png/training/9/53238.png'),Path('/storage/data/mnist_png/training/9/35444.png'),Path('/storage/data/mnist_png/training/9/34176.png')...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(im_path/\"training/9\").ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(p):\n",
    "    return torch.stack([tensor(Image.open(im)).float()/255 for im in p.ls()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3s = load_images(im_path/\"training/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(pa, pb):\n",
    "    im_as = load_images(pa)\n",
    "    im_bs = load_images(pb)\n",
    "    X = torch.cat([im_as, im_bs]).view(-1, IMAGE_SIZE)\n",
    "    Y = tensor([1] * len(im_as) + [0] * len(im_bs)).view(-1, 1)\n",
    "    \n",
    "    return DataLoader(list(zip(X, Y)), batch_size=224)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(im_path/\"training/3\", im_path/\"training/7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = get_dataloader(im_path/\"testing/3\", im_path/\"testing/7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(preds, Y):\n",
    "    return (torch.sigmoid(preds) - Y).abs().float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_accuracy(preds, Y):\n",
    "    to_lables = (torch.sigmoid(preds) > 0.5).float()\n",
    "    return (to_lables == Y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, nn.Linear(28*28, 1), opt_func=SGD, loss_func=mnist_loss, metrics=mnist_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mnist_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.651618</td>\n",
       "      <td>0.501765</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>0.330343</td>\n",
       "      <td>0.649657</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.099281</td>\n",
       "      <td>0.168122</td>\n",
       "      <td>0.847399</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.044693</td>\n",
       "      <td>0.105762</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.027031</td>\n",
       "      <td>0.076880</td>\n",
       "      <td>0.934249</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.061132</td>\n",
       "      <td>0.950442</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.018457</td>\n",
       "      <td>0.051581</td>\n",
       "      <td>0.958292</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017269</td>\n",
       "      <td>0.045453</td>\n",
       "      <td>0.964181</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.041262</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.015993</td>\n",
       "      <td>0.038195</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, lr=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Model\n",
    "\n",
    "Now we need to inspect how our model works. Specially, what are the prediction looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, _ = learn.get_preds(dl=[(X, Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there's only one value in the prediction. \n",
    "\n",
    "If that's closer to 1, we will consider it as the first category. Otherwise it's in the second category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Category Model\n",
    "\n",
    "So, then how do we create a model for multiple categories. For that, our prediction should output columns for each of those categories.\n",
    "\n",
    "This single column is knowns as an `activation`.\n",
    "\n",
    "So, for a dataset with 3 categories, we need to model outputs 3 activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_multi(pa, pb, pc):\n",
    "    im_as = load_images(pa)\n",
    "    im_bs = load_images(pb)\n",
    "    im_cs = load_images(pc)\n",
    "    X = torch.cat([im_as, im_bs, im_cs]).view(-1, IMAGE_SIZE)\n",
    "    Y = tensor([1, 0, 0] * len(im_as) + [0, 1, 0] * len(im_bs) + [0, 0, 1] * len(im_bs)).view(-1, 3)\n",
    "    \n",
    "    return DataLoader(list(zip(X, Y)), batch_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train_multi = get_dataloader_multi(im_path/\"training/1\", im_path/\"training/3\", im_path/\"training/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_valid_multi = get_dataloader_multi(im_path/\"testing/1\", im_path/\"testing/3\", im_path/\"testing/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_multi = DataLoaders(dl_train_multi, dl_train_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 784]), torch.Size([224, 3]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = dls_multi.one_batch()\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See. Now our Y field has 3 rows** <br/>\n",
    "This is what we can use for comparision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi = nn.Linear(IMAGE_SIZE, 3)\n",
    "learn_multi = Learner(dls_multi, model_multi, opt_func=SGD, loss_func=mnist_loss, metrics=mnist_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mnist_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.260804</td>\n",
       "      <td>0.371681</td>\n",
       "      <td>0.636693</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.138197</td>\n",
       "      <td>0.313874</td>\n",
       "      <td>0.698061</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.080969</td>\n",
       "      <td>0.251536</td>\n",
       "      <td>0.756623</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.058605</td>\n",
       "      <td>0.210623</td>\n",
       "      <td>0.796618</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.049866</td>\n",
       "      <td>0.181306</td>\n",
       "      <td>0.827393</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.045844</td>\n",
       "      <td>0.159674</td>\n",
       "      <td>0.849149</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.043507</td>\n",
       "      <td>0.143160</td>\n",
       "      <td>0.866423</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.041889</td>\n",
       "      <td>0.130184</td>\n",
       "      <td>0.879086</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.040702</td>\n",
       "      <td>0.119721</td>\n",
       "      <td>0.890310</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.039817</td>\n",
       "      <td>0.111100</td>\n",
       "      <td>0.899457</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_multi.fit(10, lr=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchs = [(X, Y) for X,Y in dl_valid_multi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = batchs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc955589110>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAEKUlEQVR4nO2cS2skVRSAv1vPTle/ku6845CMiUYNjC5GBBHFByKIuJlf4Mp/4lqYXyAuxJW6HBEEVzKCMihM8JGxk0kmSae704/qquqqchEy2jcycXVv4dS3PFVwDx+nzrl9q2iRpik5f2PoTiBr5EIkciESuRCJXIiE9aiLbxk3/rcj6Fbyufi3eF4hErkQiVyIRC5EIhcikQuReOTY1YH57FMM16pM3esh9g9J+gPSIFC2fuYqZPuDGW7e/Ji7H1YZvbCGOTerdP3MVIhRLCKKU8TVMc85U1COiMo2BddWmkdmhIjlBUZrM3gzPgCFYojfcCkVXaV5ZOaRGc9VaK87zFd6ADTKA4YLgrhcUJpHZoScPDMFb5/w/uJPALyxcJfC9RaDpce0QlITXHuMLcYABIlFEFmIRG0emREisx9UGZ4UsXy1RjIrpBe5CN/AGKs9gciskNbIw+kYmH6sdF3tY1e4Lobr4jcEry/8xqa7D4Af2VhDgRE9ZkKMkgf1afyrIR/N/4Apzoq2P3Jx2ymGH6Gyi2gXki7P0dmqUWt0HsoASFNAwwGm9h7S26hy8FrMqyu/6k4FyICQ2BVYpYiq5U/Ew8DG6aeIcKw0H+1CxgVBvdanYfUn4yMLtx0jfHU//SEDQmIH5rw+M5IQ49SieK9L2u0pzUd7U41dwarXom5OCnE6BvEv28rz0S4kKsGb1Z/ZsFtAiU97db46vobX1POOTL+Qcsp73hAoAfDJ3kvsfHeFld/V9o5ztPcQmX7oYp8KjJHaHeo5mRMyCBycXooxUjtuz9H2yJgbVxlsNuCKf/nNCtFWIeFKjQfXTTYWDy9e1PjNgTYhQc0meCJkvXw0Ee92i1R3Isy22v3HOfoqpGQwP99ltdCaiKd9i8JOW/mG7BxtPSSsCN5Z3Gar0ATgOB7wIDawOyYcHpP4Iy15aRMy9uDl8jardgfwOElgZzyN3RfEna6utPQJiR245hxTM85SuBMs8kXreRx9LgBdQoQgcVJWrNLDUDOaYbs9hzXU+1mbciHm7Czp8ixhXfELl/+I8ikjyh7+sgeenp3oZSgXEi5Pc/CizdrK0eU3a0C5kKhiESxFrJZOJuJJahDFhvJXlzLqhRQNvPqQefd0Iv7N8dMMbzco74aqU5pAuZDUFBTdkJI5ed5xPPQoHqTYp4+ZkKyjfOyKBILIYpg4xGlCQkpCQhBZWCGQ6G0iyoV4eyM630/zJVu8W/mRg7jKTthgeGea9a+bpN1T9JyVnaF+Y9Yd4d2f4uigzLdPbtIczbA7rFHcF4ybu6rTuYD6rfsfTWbbp9RvV7j12SuIcYqIE5aaf5KFrZpyIclgQDIYwN59zH/EsyAD8ilzgVyIRC5EIhcikQuRyIVIiPzPECbJK0QiFyKRC5HIhUjkQiRyIRJ/AQPrUWlEQlOZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(X[0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.7050, -6.2187, -6.8726],\n",
       "        [ 4.3455, -3.5186, -5.3756],\n",
       "        [ 3.5474, -3.5134, -5.5609],\n",
       "        [ 6.3068, -4.6799, -9.0990],\n",
       "        [ 4.2303, -3.7768, -8.9182],\n",
       "        [ 4.7769, -4.0494, -6.3405],\n",
       "        [ 4.5849, -6.3668, -6.7324],\n",
       "        [ 2.6792, -4.3987, -4.7453],\n",
       "        [ 4.3734, -4.2179, -4.9165],\n",
       "        [ 4.9461, -4.2549, -7.8154]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, _ = learn_multi.get_preds(dl=[(X, Y)])\n",
    "preds[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = batchs[int(len(batchs)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc910952d50>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(X[0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-5.4579,  1.3907,  3.6990],\n",
       "        [-9.6384,  3.3613,  5.1502],\n",
       "        [-1.5923,  2.5845, -1.3534],\n",
       "        [-7.6550,  3.4494,  3.5273],\n",
       "        [-8.4830,  2.3166,  5.2162],\n",
       "        [-7.0917,  6.9559, -0.3249],\n",
       "        [-6.4055,  4.5642,  1.4450],\n",
       "        [-1.3822,  2.7538, -1.9204],\n",
       "        [-6.6907, -0.6497,  6.7745],\n",
       "        [-7.2974,  1.9878,  4.5962]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, _ = learn_multi.get_preds(dl=[(X, Y)])\n",
    "preds[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = batchs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc910732710>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(X[0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-5.3952, -5.3225, 10.6378],\n",
       "        [-4.5970, -7.3094, 11.7928],\n",
       "        [-5.5610, -4.0664,  9.4223],\n",
       "        [-7.4014,  1.3143,  5.7837],\n",
       "        [-3.1736, -3.7079,  6.8055],\n",
       "        [-6.1589, -5.7271, 11.7069],\n",
       "        [-3.4800, -2.4920,  5.9694],\n",
       "        [-6.1239, -7.6321, 13.6129],\n",
       "        [-7.4626, -2.2411,  9.0126],\n",
       "        [-6.8346, -4.9073, 11.3077]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, _ = learn_multi.get_preds(dl=[(X, Y)])\n",
    "preds[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can, see our model is now have 3 activations. It had worked for us even with our exisiting loss function. If you look at the preds, the related activation is positive.\n",
    "\n",
    "But we can optimize the loss function to get some better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "We are trying to use softmax as a way to improve our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5437e-13, 6.9144e-13, 1.0000e+00])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(tensor([1, 2, 30]).float(), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(tensor([1, 2, 30]).float(), dim=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, softmax a function which converts all the numbers to get a sum of 1. This is useful for us. Because it can act as a set of probabilities.\n",
    "\n",
    "Let's try to do apply this softmax for our prediction activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 3])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.5940e-05, 9.0433e-02, 9.0947e-01],\n",
       "        [3.2380e-07, 1.4321e-01, 8.5679e-01],\n",
       "        [1.4832e-02, 9.6633e-01, 1.8833e-02],\n",
       "        [7.2299e-06, 4.8054e-01, 5.1945e-01],\n",
       "        [1.0647e-06, 5.2172e-02, 9.4783e-01],\n",
       "        [7.9232e-07, 9.9931e-01, 6.8816e-04],\n",
       "        [1.6488e-05, 9.5766e-01, 4.2324e-02],\n",
       "        [1.5592e-02, 9.7531e-01, 9.1025e-03],\n",
       "        [1.4186e-06, 5.9627e-04, 9.9940e-01],\n",
       "        [6.3650e-06, 6.8600e-02, 9.3139e-01]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need use dim=1 to mention that, we need to do apply softmax for rows.\n",
    "torch.softmax(preds, dim=1)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(preds, dim=1).sum(dim=1)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Loss Function\n",
    "\n",
    "Let's re-create our loss function based on softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss_softmax(preds, Y):\n",
    "    preds = torch.softmax(preds, dim=1)\n",
    "    return (preds - Y).abs().float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0015)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's apply that for our current preds and Y\n",
    "mnist_loss_softmax(preds, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_accuracy_softmax(preds, Y):\n",
    "    preds = torch.softmax(preds, dim=1)\n",
    "    return (((preds > 0.5).float() == Y).float().mean(dim=1) == 1).float().mean()\n",
    "mnist_accuracy_softmax(preds, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's re-run our model with that. and forget about the accucary a bit.\n",
    "learn_multi = Learner(\n",
    "    dls_multi,\n",
    "    nn.Linear(IMAGE_SIZE, 3),\n",
    "    opt_func=SGD,\n",
    "    loss_func=mnist_loss_softmax,\n",
    "    metrics=mnist_accuracy_softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mnist_accuracy_softmax</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.338504</td>\n",
       "      <td>0.439335</td>\n",
       "      <td>0.296381</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.095944</td>\n",
       "      <td>0.326698</td>\n",
       "      <td>0.529518</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.044549</td>\n",
       "      <td>0.256761</td>\n",
       "      <td>0.623483</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.032466</td>\n",
       "      <td>0.217464</td>\n",
       "      <td>0.680824</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.029093</td>\n",
       "      <td>0.190505</td>\n",
       "      <td>0.722040</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.026995</td>\n",
       "      <td>0.171364</td>\n",
       "      <td>0.750355</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.025541</td>\n",
       "      <td>0.156590</td>\n",
       "      <td>0.771728</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.024456</td>\n",
       "      <td>0.144801</td>\n",
       "      <td>0.791243</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>0.135117</td>\n",
       "      <td>0.806111</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>0.126832</td>\n",
       "      <td>0.818301</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.022575</td>\n",
       "      <td>0.119546</td>\n",
       "      <td>0.827812</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.022255</td>\n",
       "      <td>0.113060</td>\n",
       "      <td>0.837597</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.022021</td>\n",
       "      <td>0.107287</td>\n",
       "      <td>0.847218</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>0.102209</td>\n",
       "      <td>0.854433</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.021691</td>\n",
       "      <td>0.097811</td>\n",
       "      <td>0.861485</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.021561</td>\n",
       "      <td>0.094028</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.021451</td>\n",
       "      <td>0.090751</td>\n",
       "      <td>0.871269</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.021358</td>\n",
       "      <td>0.087870</td>\n",
       "      <td>0.876517</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.021279</td>\n",
       "      <td>0.085297</td>\n",
       "      <td>0.880726</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.021208</td>\n",
       "      <td>0.082967</td>\n",
       "      <td>0.883896</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.021144</td>\n",
       "      <td>0.080831</td>\n",
       "      <td>0.887449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.021084</td>\n",
       "      <td>0.078851</td>\n",
       "      <td>0.889745</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.076995</td>\n",
       "      <td>0.892041</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.020973</td>\n",
       "      <td>0.075243</td>\n",
       "      <td>0.895485</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>0.073578</td>\n",
       "      <td>0.897671</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.020870</td>\n",
       "      <td>0.071990</td>\n",
       "      <td>0.899913</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.020819</td>\n",
       "      <td>0.070475</td>\n",
       "      <td>0.901990</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>0.069031</td>\n",
       "      <td>0.903575</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.020712</td>\n",
       "      <td>0.067661</td>\n",
       "      <td>0.905488</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.020655</td>\n",
       "      <td>0.066365</td>\n",
       "      <td>0.907401</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.065143</td>\n",
       "      <td>0.908987</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.020545</td>\n",
       "      <td>0.063997</td>\n",
       "      <td>0.910790</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.020495</td>\n",
       "      <td>0.062924</td>\n",
       "      <td>0.912430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.020449</td>\n",
       "      <td>0.061921</td>\n",
       "      <td>0.913578</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.020409</td>\n",
       "      <td>0.060983</td>\n",
       "      <td>0.915327</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.020373</td>\n",
       "      <td>0.060104</td>\n",
       "      <td>0.916530</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.020342</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>0.917623</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.020313</td>\n",
       "      <td>0.058504</td>\n",
       "      <td>0.918935</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.020287</td>\n",
       "      <td>0.057771</td>\n",
       "      <td>0.919810</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.020262</td>\n",
       "      <td>0.057076</td>\n",
       "      <td>0.920739</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_multi.fit(40, lr=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, this is not **Cross Entropy Loss.**\n",
    "\n",
    "But we will get to there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
