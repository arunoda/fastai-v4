{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy Loss\n",
    "\n",
    "**WTF**. It's sounds scary. But this is a way to create a loss function for model based on categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Linear MNIST Model\n",
    "\n",
    "First of all, let's create a Linear MNIST model we create in lesson 4. <br/>\n",
    "We can build stuff on top of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/storage/data/mnist_png/training'),Path('/storage/data/mnist_png/testing')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [Path('/storage/data/mnist_png/training/9'),Path('/storage/data/mnist_png/training/6'),Path('/storage/data/mnist_png/training/7'),Path('/storage/data/mnist_png/training/0'),Path('/storage/data/mnist_png/training/4'),Path('/storage/data/mnist_png/training/5'),Path('/storage/data/mnist_png/training/3'),Path('/storage/data/mnist_png/training/2'),Path('/storage/data/mnist_png/training/1'),Path('/storage/data/mnist_png/training/8')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(im_path/\"training\").ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5949) [Path('/storage/data/mnist_png/training/9/39927.png'),Path('/storage/data/mnist_png/training/9/52230.png'),Path('/storage/data/mnist_png/training/9/39692.png'),Path('/storage/data/mnist_png/training/9/33246.png'),Path('/storage/data/mnist_png/training/9/59344.png'),Path('/storage/data/mnist_png/training/9/14364.png'),Path('/storage/data/mnist_png/training/9/53342.png'),Path('/storage/data/mnist_png/training/9/53238.png'),Path('/storage/data/mnist_png/training/9/35444.png'),Path('/storage/data/mnist_png/training/9/34176.png')...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(im_path/\"training/9\").ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(p):\n",
    "    return torch.stack([tensor(Image.open(im)).float()/255 for im in p.ls()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3s = load_images(im_path/\"training/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(pa, pb):\n",
    "    im_as = load_images(pa)\n",
    "    im_bs = load_images(pb)\n",
    "    X = torch.cat([im_as, im_bs]).view(-1, IMAGE_SIZE)\n",
    "    Y = tensor([1] * len(im_as) + [0] * len(im_bs)).view(-1, 1)\n",
    "    \n",
    "    return DataLoader(list(zip(X, Y)), batch_size=224)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(im_path/\"training/3\", im_path/\"training/7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = get_dataloader(im_path/\"testing/3\", im_path/\"testing/7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(preds, Y):\n",
    "    return (torch.sigmoid(preds) - Y.view(-1, 1)).abs().float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_accuracy(preds, Y):\n",
    "    to_lables = (torch.sigmoid(preds) > 0.5).float()\n",
    "    return (to_lables == Y.view(-1,1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, nn.Linear(28*28, 1), opt_func=SGD, loss_func=mnist_loss, metrics=mnist_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mnist_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.651437</td>\n",
       "      <td>0.502142</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.299171</td>\n",
       "      <td>0.328655</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.105245</td>\n",
       "      <td>0.164759</td>\n",
       "      <td>0.851325</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.046964</td>\n",
       "      <td>0.103726</td>\n",
       "      <td>0.911678</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.028009</td>\n",
       "      <td>0.075490</td>\n",
       "      <td>0.935231</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.021385</td>\n",
       "      <td>0.060149</td>\n",
       "      <td>0.950932</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.018733</td>\n",
       "      <td>0.050874</td>\n",
       "      <td>0.958292</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>0.044946</td>\n",
       "      <td>0.965162</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.016672</td>\n",
       "      <td>0.040895</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.016112</td>\n",
       "      <td>0.037926</td>\n",
       "      <td>0.967615</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, lr=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Model\n",
    "\n",
    "Now we need to inspect how our model works. Specially, what are the prediction looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, _ = learn.get_preds(dl=[(X, Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there's only one value in the prediction. \n",
    "\n",
    "If that's closer to 1, we will consider it as the first category. Otherwise it's in the second category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Category Model\n",
    "\n",
    "So, then how do we create a model for multiple categories. For that, our prediction should output columns for each of those categories.\n",
    "\n",
    "This single column is knowns as an `activation`.\n",
    "\n",
    "So, for a dataset with 3 categories, we need to model outputs 3 activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_multi(pa, pb, pc):\n",
    "    im_as = load_images(pa)\n",
    "    im_bs = load_images(pb)\n",
    "    im_cs = load_images(pc)\n",
    "    X = torch.cat([im_as, im_bs, im_cs]).view(-1, IMAGE_SIZE)\n",
    "    ## See. Now we identify each category by an index.\n",
    "    Y = tensor([0] * len(im_as) + [1] * len(im_bs) + [2] * len(im_bs)).view(-1)\n",
    "    \n",
    "    return DataLoader(list(zip(X, Y)), batch_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train_multi = get_dataloader_multi(im_path/\"training/1\", im_path/\"training/3\", im_path/\"training/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_valid_multi = get_dataloader_multi(im_path/\"testing/1\", im_path/\"testing/3\", im_path/\"testing/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_multi = DataLoaders(dl_train_multi, dl_train_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 784]), torch.Size([224]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = dls_multi.one_batch()\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi = nn.Linear(IMAGE_SIZE, 3)\n",
    "learn_multi = Learner(dls_multi, model_multi, opt_func=SGD, loss_func=mnist_loss, metrics=mnist_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mnist_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.627902</td>\n",
       "      <td>0.630273</td>\n",
       "      <td>0.335137</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.532805</td>\n",
       "      <td>0.510623</td>\n",
       "      <td>0.500947</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.511580</td>\n",
       "      <td>0.420939</td>\n",
       "      <td>0.620823</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.505835</td>\n",
       "      <td>0.377360</td>\n",
       "      <td>0.655935</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.503563</td>\n",
       "      <td>0.355297</td>\n",
       "      <td>0.670748</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.502232</td>\n",
       "      <td>0.343041</td>\n",
       "      <td>0.677709</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.501258</td>\n",
       "      <td>0.335566</td>\n",
       "      <td>0.681826</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.500478</td>\n",
       "      <td>0.330637</td>\n",
       "      <td>0.684104</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.499826</td>\n",
       "      <td>0.327177</td>\n",
       "      <td>0.686017</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.499268</td>\n",
       "      <td>0.324628</td>\n",
       "      <td>0.687621</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_multi.fit(10, lr=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchs = [batch for batch in dl_valid_multi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = batchs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa99dd4e950>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAEKUlEQVR4nO2cS2skVRSAv1vPTle/ku6845CMiUYNjC5GBBHFByKIuJlf4Mp/4lqYXyAuxJW6HBEEVzKCMihM8JGxk0kmSae704/qquqqchEy2jcycXVv4dS3PFVwDx+nzrl9q2iRpik5f2PoTiBr5EIkciESuRCJXIiE9aiLbxk3/rcj6Fbyufi3eF4hErkQiVyIRC5EIhcikQuReOTY1YH57FMM16pM3esh9g9J+gPSIFC2fuYqZPuDGW7e/Ji7H1YZvbCGOTerdP3MVIhRLCKKU8TVMc85U1COiMo2BddWmkdmhIjlBUZrM3gzPgCFYojfcCkVXaV5ZOaRGc9VaK87zFd6ADTKA4YLgrhcUJpHZoScPDMFb5/w/uJPALyxcJfC9RaDpce0QlITXHuMLcYABIlFEFmIRG0emREisx9UGZ4UsXy1RjIrpBe5CN/AGKs9gciskNbIw+kYmH6sdF3tY1e4Lobr4jcEry/8xqa7D4Af2VhDgRE9ZkKMkgf1afyrIR/N/4Apzoq2P3Jx2ymGH6Gyi2gXki7P0dmqUWt0HsoASFNAwwGm9h7S26hy8FrMqyu/6k4FyICQ2BVYpYiq5U/Ew8DG6aeIcKw0H+1CxgVBvdanYfUn4yMLtx0jfHU//SEDQmIH5rw+M5IQ49SieK9L2u0pzUd7U41dwarXom5OCnE6BvEv28rz0S4kKsGb1Z/ZsFtAiU97db46vobX1POOTL+Qcsp73hAoAfDJ3kvsfHeFld/V9o5ztPcQmX7oYp8KjJHaHeo5mRMyCBycXooxUjtuz9H2yJgbVxlsNuCKf/nNCtFWIeFKjQfXTTYWDy9e1PjNgTYhQc0meCJkvXw0Ee92i1R3Isy22v3HOfoqpGQwP99ltdCaiKd9i8JOW/mG7BxtPSSsCN5Z3Gar0ATgOB7wIDawOyYcHpP4Iy15aRMy9uDl8jardgfwOElgZzyN3RfEna6utPQJiR245hxTM85SuBMs8kXreRx9LgBdQoQgcVJWrNLDUDOaYbs9hzXU+1mbciHm7Czp8ixhXfELl/+I8ikjyh7+sgeenp3oZSgXEi5Pc/CizdrK0eU3a0C5kKhiESxFrJZOJuJJahDFhvJXlzLqhRQNvPqQefd0Iv7N8dMMbzco74aqU5pAuZDUFBTdkJI5ed5xPPQoHqTYp4+ZkKyjfOyKBILIYpg4xGlCQkpCQhBZWCGQ6G0iyoV4eyM630/zJVu8W/mRg7jKTthgeGea9a+bpN1T9JyVnaF+Y9Yd4d2f4uigzLdPbtIczbA7rFHcF4ybu6rTuYD6rfsfTWbbp9RvV7j12SuIcYqIE5aaf5KFrZpyIclgQDIYwN59zH/EsyAD8ilzgVyIRC5EIhcikQuRyIVIiPzPECbJK0QiFyKRC5HIhUjkQiRyIRJ/AQPrUWlEQlOZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(X[0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-5.7405, -5.7780, -5.7669],\n",
       "        [-4.4194, -4.2997, -4.3951],\n",
       "        [-3.6653, -3.6389, -3.5616],\n",
       "        [-6.3218, -6.2866, -6.3717],\n",
       "        [-4.2471, -4.2011, -4.2788],\n",
       "        [-4.7459, -4.7244, -4.7490],\n",
       "        [-4.5886, -4.5865, -4.5801],\n",
       "        [-2.5983, -2.5662, -2.5797],\n",
       "        [-4.3491, -4.2793, -4.4242],\n",
       "        [-4.9524, -4.8869, -4.9290]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, _ = learn_multi.get_preds(dl=[(X, Y)])\n",
    "preds[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = batchs[int(len(batchs)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa968733750>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(X[0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[10.2620, 10.4223, 10.4604],\n",
       "        [17.5421, 17.4771, 17.4407],\n",
       "        [ 5.2040,  5.4254,  5.2564],\n",
       "        [14.5555, 14.6538, 14.6453],\n",
       "        [13.8610, 13.9010, 13.8870],\n",
       "        [14.5766, 14.5162, 14.3017],\n",
       "        [11.4736, 11.4081, 11.3763],\n",
       "        [ 6.3311,  6.4556,  6.3794],\n",
       "        [12.7666, 12.7108, 12.7468],\n",
       "        [12.5406, 12.5752, 12.5830]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, _ = learn_multi.get_preds(dl=[(X, Y)])\n",
    "preds[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = batchs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa968696310>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(X[0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.4873,  9.5662,  9.3157],\n",
       "        [10.6689, 10.6926, 10.7215],\n",
       "        [ 9.2993,  9.3801,  9.3614],\n",
       "        [13.2644, 13.3351, 13.4412],\n",
       "        [ 6.1129,  6.1647,  6.0163],\n",
       "        [11.3574, 11.2805, 11.3654],\n",
       "        [ 6.4282,  6.4481,  6.4038],\n",
       "        [11.1848, 11.2088, 11.1805],\n",
       "        [12.9418, 12.7778, 12.8554],\n",
       "        [12.1056, 12.1029, 12.0906]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, _ = learn_multi.get_preds(dl=[(X, Y)])\n",
    "preds[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can, see our model is now have 3 activations. It had worked for us even with our exisiting loss function.\n",
    "\n",
    "But that's mostly due to the randomness and training. The current loss function is not suited for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "We are trying to use softmax as a way to improve our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5437e-13, 6.9144e-13, 1.0000e+00])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(tensor([1, 2, 30]).float(), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(tensor([1, 2, 30]).float(), dim=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, softmax a function which converts all the numbers to get a sum of 1. This is useful for us. Because it can act as a set of probabilities.\n",
    "\n",
    "Let's try to do apply this softmax for our prediction activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 3])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3419, 0.3700, 0.2880],\n",
       "        [0.3249, 0.3327, 0.3424],\n",
       "        [0.3176, 0.3444, 0.3380],\n",
       "        [0.3061, 0.3285, 0.3653],\n",
       "        [0.3377, 0.3557, 0.3066],\n",
       "        [0.3408, 0.3156, 0.3436],\n",
       "        [0.3338, 0.3405, 0.3257],\n",
       "        [0.3311, 0.3392, 0.3297],\n",
       "        [0.3615, 0.3068, 0.3316],\n",
       "        [0.3353, 0.3344, 0.3303]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need use dim=1 to mention that, we need to do apply softmax for rows.\n",
    "torch.softmax(preds, dim=1)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(preds, dim=1).sum(dim=1)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Loss Function\n",
    "\n",
    "Let's re-create our loss function based on softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3312)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_loss_softmax(preds, Y):\n",
    "    preds = torch.softmax(preds, dim=1)\n",
    "    # Why put minus.\n",
    "    # Here we are using a probability. Larger the probability better.\n",
    "    # But to make a loss we need minus it.\n",
    "    length = len(preds)\n",
    "    return -(preds[range(length), Y]).mean()\n",
    "\n",
    "mnist_loss_softmax(preds, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_accuracy_softmax(preds, Y):\n",
    "    preds = torch.softmax(preds, dim=1)\n",
    "    length = len(preds)\n",
    "    probs = preds[range(length), Y]\n",
    "    \n",
    "    return (probs > 0.5).float().mean()\n",
    "\n",
    "mnist_accuracy_softmax(preds, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's re-run our model with that. and forget about the accucary a bit.\n",
    "learn_multi = Learner(\n",
    "    dls_multi,\n",
    "    nn.Linear(IMAGE_SIZE, 3),\n",
    "    opt_func=SGD,\n",
    "    loss_func=mnist_loss_softmax,\n",
    "    metrics=mnist_accuracy_softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mnist_accuracy_softmax</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.534382</td>\n",
       "      <td>-0.385193</td>\n",
       "      <td>0.326883</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.738940</td>\n",
       "      <td>-0.550139</td>\n",
       "      <td>0.566962</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.912823</td>\n",
       "      <td>-0.608303</td>\n",
       "      <td>0.614846</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.952106</td>\n",
       "      <td>-0.660613</td>\n",
       "      <td>0.665683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.960815</td>\n",
       "      <td>-0.702584</td>\n",
       "      <td>0.708593</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.964091</td>\n",
       "      <td>-0.734181</td>\n",
       "      <td>0.740407</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-0.966199</td>\n",
       "      <td>-0.758242</td>\n",
       "      <td>0.764677</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>-0.967726</td>\n",
       "      <td>-0.776628</td>\n",
       "      <td>0.783918</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>-0.969013</td>\n",
       "      <td>-0.790694</td>\n",
       "      <td>0.798404</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-0.969975</td>\n",
       "      <td>-0.802001</td>\n",
       "      <td>0.809664</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_multi.fit(10, lr=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, this is not **Cross Entropy Loss.**\n",
    "\n",
    "But we will get to there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using log function\n",
    "\n",
    "With softmax we got a probability. But it does not track improvements nicely.\n",
    "Because 0.9 vs 0.999 is quite bit improvement.\n",
    "\n",
    "But the linear range does not show that. That's why we need to apply log. Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's plot the function first\n",
    "plot_function(torch.log, min=0, max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1081)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_loss_softmax_log(preds, Y):\n",
    "    preds = torch.softmax(preds, dim=1)\n",
    "    # Why put minus.\n",
    "    # Here we are using a probability. Larger the probability better.\n",
    "    # But to make a loss we need minus it.\n",
    "    length = len(preds)\n",
    "    probs = preds[range(length), Y]\n",
    "    return -(torch.log(probs)).mean()\n",
    "\n",
    "mnist_loss_softmax_log(preds, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1081)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(preds, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See. Both are the same.**\n",
    "\n",
    "Let's train it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_multi = Learner(\n",
    "    dls_multi,\n",
    "    nn.Linear(IMAGE_SIZE, 3),\n",
    "    opt_func=SGD,\n",
    "    loss_func=mnist_loss_softmax_log,\n",
    "    metrics=mnist_accuracy_softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mnist_accuracy_softmax</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.517141</td>\n",
       "      <td>6.664789</td>\n",
       "      <td>0.296381</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.277105</td>\n",
       "      <td>7.573242</td>\n",
       "      <td>0.604297</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.464094</td>\n",
       "      <td>5.588078</td>\n",
       "      <td>0.655734</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.281802</td>\n",
       "      <td>2.199331</td>\n",
       "      <td>0.791516</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.153967</td>\n",
       "      <td>1.824374</td>\n",
       "      <td>0.814475</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.113647</td>\n",
       "      <td>1.620121</td>\n",
       "      <td>0.825681</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.094880</td>\n",
       "      <td>1.494528</td>\n",
       "      <td>0.831857</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.083422</td>\n",
       "      <td>1.406748</td>\n",
       "      <td>0.835738</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075585</td>\n",
       "      <td>1.339194</td>\n",
       "      <td>0.837706</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069779</td>\n",
       "      <td>1.286042</td>\n",
       "      <td>0.840385</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_multi.fit(10, lr=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As you can see, it trains much better compared with `mnist_loss_softmax`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
