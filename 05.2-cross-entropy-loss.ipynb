{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy Loss\n",
    "\n",
    "**WTF**. It's sounds scary. But this is a way to create a loss function for model based on categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Linear MNIST Model\n",
    "\n",
    "First of all, let's create a Linear MNIST model we create in lesson 4. <br/>\n",
    "We can build stuff on top of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/storage/data/mnist_png/training'),Path('/storage/data/mnist_png/testing')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [Path('/storage/data/mnist_png/training/9'),Path('/storage/data/mnist_png/training/6'),Path('/storage/data/mnist_png/training/7'),Path('/storage/data/mnist_png/training/0'),Path('/storage/data/mnist_png/training/4'),Path('/storage/data/mnist_png/training/5'),Path('/storage/data/mnist_png/training/3'),Path('/storage/data/mnist_png/training/2'),Path('/storage/data/mnist_png/training/1'),Path('/storage/data/mnist_png/training/8')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(im_path/\"training\").ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5949) [Path('/storage/data/mnist_png/training/9/39927.png'),Path('/storage/data/mnist_png/training/9/52230.png'),Path('/storage/data/mnist_png/training/9/39692.png'),Path('/storage/data/mnist_png/training/9/33246.png'),Path('/storage/data/mnist_png/training/9/59344.png'),Path('/storage/data/mnist_png/training/9/14364.png'),Path('/storage/data/mnist_png/training/9/53342.png'),Path('/storage/data/mnist_png/training/9/53238.png'),Path('/storage/data/mnist_png/training/9/35444.png'),Path('/storage/data/mnist_png/training/9/34176.png')...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(im_path/\"training/9\").ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(p):\n",
    "    return torch.stack([tensor(Image.open(im)).float()/255 for im in p.ls()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3s = load_images(im_path/\"training/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(pa, pb):\n",
    "    im_as = load_images(pa)\n",
    "    im_bs = load_images(pb)\n",
    "    X = torch.cat([im_as, im_bs]).view(-1, IMAGE_SIZE)\n",
    "    Y = tensor([1] * len(im_as) + [0] * len(im_bs)).view(-1, 1)\n",
    "    \n",
    "    return DataLoader(list(zip(X, Y)), batch_size=224)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(im_path/\"training/3\", im_path/\"training/7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = get_dataloader(im_path/\"testing/3\", im_path/\"testing/7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(preds, Y):\n",
    "    return (torch.sigmoid(preds) - Y).abs().float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_accuracy(preds, Y):\n",
    "    to_lables = (torch.sigmoid(preds) > 0.5).float()\n",
    "    return (to_lables == Y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, nn.Linear(28*28, 1), opt_func=SGD, loss_func=mnist_loss, metrics=mnist_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mnist_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.620795</td>\n",
       "      <td>0.119067</td>\n",
       "      <td>0.927380</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.164949</td>\n",
       "      <td>0.260446</td>\n",
       "      <td>0.752699</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.063917</td>\n",
       "      <td>0.131768</td>\n",
       "      <td>0.885672</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.033326</td>\n",
       "      <td>0.088947</td>\n",
       "      <td>0.923454</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023218</td>\n",
       "      <td>0.067867</td>\n",
       "      <td>0.942591</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.019471</td>\n",
       "      <td>0.055745</td>\n",
       "      <td>0.954858</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.017824</td>\n",
       "      <td>0.048204</td>\n",
       "      <td>0.962709</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.016921</td>\n",
       "      <td>0.043211</td>\n",
       "      <td>0.964671</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.016309</td>\n",
       "      <td>0.039665</td>\n",
       "      <td>0.966143</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.015841</td>\n",
       "      <td>0.036985</td>\n",
       "      <td>0.968597</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, lr=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Model\n",
    "\n",
    "Now we need to inspect how our model works. Specially, what are the prediction looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, _ = learn.get_preds(dl=[(X, Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there's only one value in the prediction. \n",
    "\n",
    "If that's closer to 1, we will consider it as the first category. Otherwise it's in the second category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Category Model\n",
    "\n",
    "So, then how do we create a model for multiple categories. For that, our prediction should output columns for each of those categories.\n",
    "\n",
    "This single column is knowns as an `activation`.\n",
    "\n",
    "So, for a dataset with 3 categories, we need to model outputs 3 activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_multi(pa, pb, pc):\n",
    "    im_as = load_images(pa)\n",
    "    im_bs = load_images(pb)\n",
    "    im_cs = load_images(pc)\n",
    "    X = torch.cat([im_as, im_bs, im_cs]).view(-1, IMAGE_SIZE)\n",
    "    ## See. Now we identify each category by an index.\n",
    "    Y = tensor([0] * len(im_as) + [1] * len(im_bs) + [2] * len(im_bs)).view(-1, 1)\n",
    "    \n",
    "    return DataLoader(list(zip(X, Y)), batch_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train_multi = get_dataloader_multi(im_path/\"training/1\", im_path/\"training/3\", im_path/\"training/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_valid_multi = get_dataloader_multi(im_path/\"testing/1\", im_path/\"testing/3\", im_path/\"testing/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_multi = DataLoaders(dl_train_multi, dl_train_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 784]), torch.Size([224, 1]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = dls_multi.one_batch()\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi = nn.Linear(IMAGE_SIZE, 3)\n",
    "learn_multi = Learner(dls_multi, model_multi, opt_func=SGD, loss_func=mnist_loss, metrics=mnist_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mnist_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.625724</td>\n",
       "      <td>0.630046</td>\n",
       "      <td>0.335137</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.532421</td>\n",
       "      <td>0.510060</td>\n",
       "      <td>0.501549</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.511503</td>\n",
       "      <td>0.420584</td>\n",
       "      <td>0.621424</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.505808</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>0.656317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.503542</td>\n",
       "      <td>0.355136</td>\n",
       "      <td>0.670876</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.502210</td>\n",
       "      <td>0.342919</td>\n",
       "      <td>0.678018</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.501235</td>\n",
       "      <td>0.335468</td>\n",
       "      <td>0.681717</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.500453</td>\n",
       "      <td>0.330553</td>\n",
       "      <td>0.684250</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.499800</td>\n",
       "      <td>0.327104</td>\n",
       "      <td>0.686181</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.499243</td>\n",
       "      <td>0.324562</td>\n",
       "      <td>0.687930</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_multi.fit(10, lr=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchs = [(X, Y) for X,Y in dl_valid_multi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = batchs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9d58a4ab10>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAEKUlEQVR4nO2cS2skVRSAv1vPTle/ku6845CMiUYNjC5GBBHFByKIuJlf4Mp/4lqYXyAuxJW6HBEEVzKCMihM8JGxk0kmSae704/qquqqchEy2jcycXVv4dS3PFVwDx+nzrl9q2iRpik5f2PoTiBr5EIkciESuRCJXIiE9aiLbxk3/rcj6Fbyufi3eF4hErkQiVyIRC5EIhcikQuReOTY1YH57FMM16pM3esh9g9J+gPSIFC2fuYqZPuDGW7e/Ji7H1YZvbCGOTerdP3MVIhRLCKKU8TVMc85U1COiMo2BddWmkdmhIjlBUZrM3gzPgCFYojfcCkVXaV5ZOaRGc9VaK87zFd6ADTKA4YLgrhcUJpHZoScPDMFb5/w/uJPALyxcJfC9RaDpce0QlITXHuMLcYABIlFEFmIRG0emREisx9UGZ4UsXy1RjIrpBe5CN/AGKs9gciskNbIw+kYmH6sdF3tY1e4Lobr4jcEry/8xqa7D4Af2VhDgRE9ZkKMkgf1afyrIR/N/4Apzoq2P3Jx2ymGH6Gyi2gXki7P0dmqUWt0HsoASFNAwwGm9h7S26hy8FrMqyu/6k4FyICQ2BVYpYiq5U/Ew8DG6aeIcKw0H+1CxgVBvdanYfUn4yMLtx0jfHU//SEDQmIH5rw+M5IQ49SieK9L2u0pzUd7U41dwarXom5OCnE6BvEv28rz0S4kKsGb1Z/ZsFtAiU97db46vobX1POOTL+Qcsp73hAoAfDJ3kvsfHeFld/V9o5ztPcQmX7oYp8KjJHaHeo5mRMyCBycXooxUjtuz9H2yJgbVxlsNuCKf/nNCtFWIeFKjQfXTTYWDy9e1PjNgTYhQc0meCJkvXw0Ee92i1R3Isy22v3HOfoqpGQwP99ltdCaiKd9i8JOW/mG7BxtPSSsCN5Z3Gar0ATgOB7wIDawOyYcHpP4Iy15aRMy9uDl8jardgfwOElgZzyN3RfEna6utPQJiR245hxTM85SuBMs8kXreRx9LgBdQoQgcVJWrNLDUDOaYbs9hzXU+1mbciHm7Czp8ixhXfELl/+I8ikjyh7+sgeenp3oZSgXEi5Pc/CizdrK0eU3a0C5kKhiESxFrJZOJuJJahDFhvJXlzLqhRQNvPqQefd0Iv7N8dMMbzco74aqU5pAuZDUFBTdkJI5ed5xPPQoHqTYp4+ZkKyjfOyKBILIYpg4xGlCQkpCQhBZWCGQ6G0iyoV4eyM630/zJVu8W/mRg7jKTthgeGea9a+bpN1T9JyVnaF+Y9Yd4d2f4uigzLdPbtIczbA7rFHcF4ybu6rTuYD6rfsfTWbbp9RvV7j12SuIcYqIE5aaf5KFrZpyIclgQDIYwN59zH/EsyAD8ilzgVyIRC5EIhcikQuRyIVIiPzPECbJK0QiFyKRC5HIhUjkQiRyIRJ/AQPrUWlEQlOZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(X[0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-5.7364, -5.7292, -5.7618],\n",
       "        [-4.4396, -4.3240, -4.3491],\n",
       "        [-3.5968, -3.6263, -3.5618],\n",
       "        [-6.2857, -6.3388, -6.3670],\n",
       "        [-4.2157, -4.2627, -4.1498],\n",
       "        [-4.7434, -4.7533, -4.7693],\n",
       "        [-4.6218, -4.5821, -4.5795],\n",
       "        [-2.5519, -2.6448, -2.6019],\n",
       "        [-4.4160, -4.3615, -4.3577],\n",
       "        [-4.9493, -4.8949, -4.9307]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, _ = learn_multi.get_preds(dl=[(X, Y)])\n",
    "preds[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = batchs[int(len(batchs)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9d5017c050>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(X[0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[10.2571, 10.3083, 10.3254],\n",
       "        [17.2409, 17.4715, 17.4188],\n",
       "        [ 5.3463,  5.3424,  5.2992],\n",
       "        [14.5205, 14.5418, 14.5055],\n",
       "        [13.7440, 14.0344, 13.9420],\n",
       "        [14.3314, 14.4772, 14.4610],\n",
       "        [11.3035, 11.4784, 11.5185],\n",
       "        [ 6.2877,  6.4514,  6.3502],\n",
       "        [12.5024, 12.6683, 12.6422],\n",
       "        [12.4961, 12.6083, 12.6317]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, _ = learn_multi.get_preds(dl=[(X, Y)])\n",
    "preds[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = batchs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9d501a33d0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(X[0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.2959,  9.2812,  9.4774],\n",
       "        [10.6278, 10.5437, 10.6662],\n",
       "        [ 9.3409,  9.3723,  9.4077],\n",
       "        [13.4009, 13.3765, 13.3672],\n",
       "        [ 6.0300,  6.1146,  5.9489],\n",
       "        [11.3884, 11.2243, 11.4415],\n",
       "        [ 6.4599,  6.3190,  6.4792],\n",
       "        [11.1509, 11.2363, 11.0460],\n",
       "        [12.6472, 12.8648, 12.9999],\n",
       "        [12.2484, 12.2540, 12.1645]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, _ = learn_multi.get_preds(dl=[(X, Y)])\n",
    "preds[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can, see our model is now have 3 activations. It had worked for us even with our exisiting loss function.\n",
    "\n",
    "But that's mostly due to the randomness and training. The current loss function is not suited for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "We are trying to use softmax as a way to improve our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5437e-13, 6.9144e-13, 1.0000e+00])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(tensor([1, 2, 30]).float(), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(tensor([1, 2, 30]).float(), dim=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, softmax a function which converts all the numbers to get a sum of 1. This is useful for us. Because it can act as a set of probabilities.\n",
    "\n",
    "Let's try to do apply this softmax for our prediction activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 3])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3140, 0.3095, 0.3765],\n",
       "        [0.3380, 0.3107, 0.3512],\n",
       "        [0.3225, 0.3328, 0.3448],\n",
       "        [0.3398, 0.3316, 0.3286],\n",
       "        [0.3322, 0.3615, 0.3063],\n",
       "        [0.3444, 0.2923, 0.3632],\n",
       "        [0.3462, 0.3008, 0.3530],\n",
       "        [0.3345, 0.3643, 0.3012],\n",
       "        [0.2728, 0.3391, 0.3881],\n",
       "        [0.3419, 0.3438, 0.3144]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need use dim=1 to mention that, we need to do apply softmax for rows.\n",
    "torch.softmax(preds, dim=1)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(preds, dim=1).sum(dim=1)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Loss Function\n",
    "\n",
    "Let's re-create our loss function based on softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3356)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_loss_softmax(preds, Y):\n",
    "    preds = torch.softmax(preds, dim=1)\n",
    "    # Why put minus.\n",
    "    # Here we are using a probability. Larger the probability better.\n",
    "    # But to make a loss we need minus it.\n",
    "    length = len(preds)\n",
    "    return -(preds[range(length), Y.view(length)]).mean()\n",
    "\n",
    "mnist_loss_softmax(preds, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_accuracy_softmax(preds, Y):\n",
    "    preds = torch.softmax(preds, dim=1)\n",
    "    length = len(preds)\n",
    "    probs = preds[range(length), Y.view(length)]\n",
    "    \n",
    "    return (probs > 0.5).float().mean()\n",
    "\n",
    "mnist_accuracy_softmax(preds, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's re-run our model with that. and forget about the accucary a bit.\n",
    "learn_multi = Learner(\n",
    "    dls_multi,\n",
    "    nn.Linear(IMAGE_SIZE, 3),\n",
    "    opt_func=SGD,\n",
    "    loss_func=mnist_loss_softmax,\n",
    "    metrics=mnist_accuracy_softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mnist_accuracy_softmax</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.566194</td>\n",
       "      <td>-0.399019</td>\n",
       "      <td>0.363944</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.797742</td>\n",
       "      <td>-0.543924</td>\n",
       "      <td>0.559582</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.924973</td>\n",
       "      <td>-0.608963</td>\n",
       "      <td>0.615666</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.954805</td>\n",
       "      <td>-0.660544</td>\n",
       "      <td>0.665027</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.961763</td>\n",
       "      <td>-0.702412</td>\n",
       "      <td>0.707773</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.964645</td>\n",
       "      <td>-0.733817</td>\n",
       "      <td>0.740243</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-0.966318</td>\n",
       "      <td>-0.757670</td>\n",
       "      <td>0.765005</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>-0.967753</td>\n",
       "      <td>-0.775815</td>\n",
       "      <td>0.783208</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>-0.969041</td>\n",
       "      <td>-0.789752</td>\n",
       "      <td>0.797311</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-0.969976</td>\n",
       "      <td>-0.801078</td>\n",
       "      <td>0.808079</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_multi.fit(10, lr=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, this is not **Cross Entropy Loss.**\n",
    "\n",
    "But we will get to there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using log function\n",
    "\n",
    "With softmax we got a probability. But it does not track improvements nicely.\n",
    "Because 0.9 vs 0.999 is quite bit improvement.\n",
    "\n",
    "But the linear range does not show that. That's why we need to apply log. Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0950)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_loss_softmax_log(preds, Y):\n",
    "    preds = torch.softmax(preds, dim=1)\n",
    "    # Why put minus.\n",
    "    # Here we are using a probability. Larger the probability better.\n",
    "    # But to make a loss we need minus it.\n",
    "    length = len(preds)\n",
    "    probs = preds[range(length), Y.view(length)]\n",
    "    return -(torch.log(probs)).mean()\n",
    "\n",
    "mnist_loss_softmax_log(preds, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0950)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(preds, Y.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See. Both are the same.**\n",
    "\n",
    "Let's train it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_multi = Learner(\n",
    "    dls_multi,\n",
    "    nn.Linear(IMAGE_SIZE, 3),\n",
    "    opt_func=SGD,\n",
    "    loss_func=mnist_loss_softmax_log,\n",
    "    metrics=mnist_accuracy_softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mnist_accuracy_softmax</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.505990</td>\n",
       "      <td>6.047721</td>\n",
       "      <td>0.300426</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.282377</td>\n",
       "      <td>7.202853</td>\n",
       "      <td>0.604187</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.448350</td>\n",
       "      <td>5.334094</td>\n",
       "      <td>0.656499</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.271790</td>\n",
       "      <td>2.170514</td>\n",
       "      <td>0.789330</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.149297</td>\n",
       "      <td>1.811164</td>\n",
       "      <td>0.812124</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.110740</td>\n",
       "      <td>1.612693</td>\n",
       "      <td>0.823713</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.092817</td>\n",
       "      <td>1.489796</td>\n",
       "      <td>0.830600</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.081893</td>\n",
       "      <td>1.403291</td>\n",
       "      <td>0.834263</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074408</td>\n",
       "      <td>1.336439</td>\n",
       "      <td>0.836668</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068877</td>\n",
       "      <td>1.283694</td>\n",
       "      <td>0.839237</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_multi.fit(10, lr=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As you can see, it trains much better compared with `mnist_loss_softmax`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
